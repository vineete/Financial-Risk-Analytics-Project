{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import statsmodels.api as sma\n",
    "\n",
    "from keras.models import Sequential \n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"final_non_time_data.csv\")\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_columns = [\"BorrZip\",\"CDC_Name\",\"CDC_Zip\",\"LoanSum\",\"TermInMonths\",\"BusinessType\", 'subpgmdesc',\n",
    "       'NaicsCode','unemp_comp', 'biz_net_income', 'adj_gross_income',\n",
    "       'net_cap_gain', 'total_tax_liab', '2018-2010', '2010-2000',\n",
    "       '2000-1990',\"P/E_t0\",\"unemp_t0\",\"interest_rate_t0\",\"GDPchange_t0\",\"LoanStatusCat\"]\n",
    "data_selected = data[selected_columns]\n",
    "print(data_selected.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in data_selected.columns:\n",
    "    if data_selected[col].isna().sum() > 0:\n",
    "        print(\"column \", col, \" has \", data_selected[col].isna().sum(), \" NA values\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_selected[\"CDC_Zip\"] = data_selected[\"CDC_Zip\"].fillna(-1)\n",
    "data_selected[\"BusinessType\"] = data_selected[\"BusinessType\"].fillna(\"Unknown\") \n",
    "data_selected[\"NaicsCode\"] = data_selected[\"NaicsCode\"].fillna(-1)\n",
    "data_selected[\"2018-2010\"] = data_selected[\"2018-2010\"].fillna(data_selected[\"2018-2010\"].mean())\n",
    "data_selected[\"2010-2000\"] = data_selected[\"2010-2000\"].fillna(data_selected[\"2010-2000\"].mean())\n",
    "data_selected[\"2000-1990\"] = data_selected[\"2000-1990\"].fillna(data_selected[\"2000-1990\"].mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for col in data_selected.columns:\n",
    "    if data_selected[col].isna().sum() > 0:\n",
    "        count += 1\n",
    "        print(\"column \", col, \" has \", data_selected[col].isna().sum(), \" NA values\") \n",
    "if count == 0:\n",
    "    print(\"All good!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_selected.head())\n",
    "print(data_selected.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le1 = LabelEncoder()\n",
    "data_selected[\"CDC_Name\"] = le1.fit_transform(data_selected[\"CDC_Name\"])\n",
    "\n",
    "le2 = LabelEncoder()\n",
    "data_selected[\"BusinessType\"] = le2.fit_transform(data_selected[\"BusinessType\"])\n",
    "\n",
    "le3 = LabelEncoder()\n",
    "data_selected[\"subpgmdesc\"] = le3.fit_transform(data_selected[\"subpgmdesc\"])\n",
    "\n",
    "\n",
    "le5 = LabelEncoder()\n",
    "data_selected[\"BorrZip\"] = le5.fit_transform(data_selected[\"BorrZip\"])\n",
    "\n",
    "le6 = LabelEncoder()\n",
    "data_selected[\"CDC_Zip\"] = le6.fit_transform(data_selected[\"CDC_Zip\"])\n",
    "\n",
    "le7 = LabelEncoder()\n",
    "data_selected[\"NaicsCode\"] = le7.fit_transform(data_selected[\"NaicsCode\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\"\"\"\n",
    "sc1 = StandardScaler()\n",
    "data_selected[\"LoanSum\"] = sc1.fit_transform(np.array(data_selected[\"LoanSum\"]).reshape(-1,1))\n",
    "\n",
    "sc2 = StandardScaler()\n",
    "data_selected[\"TermInMonths\"] = sc2.fit_transform(np.array(data_selected[\"TermInMonths\"]).reshape(-1,1))\n",
    "\n",
    "sc3 = StandardScaler()\n",
    "data_selected[\"unemp_comp\"] = sc3.fit_transform(np.array(data_selected[\"unemp_comp\"]).reshape(-1,1))\n",
    "\n",
    "sc4 = StandardScaler()\n",
    "data_selected[\"biz_net_income\"] = sc4.fit_transform(np.array(data_selected[\"biz_net_income\"]).reshape(-1,1))\n",
    "\n",
    "sc5 = StandardScaler()\n",
    "data_selected[\"adj_gross_income\"] = sc5.fit_transform(np.array(data_selected[\"adj_gross_income\"]).reshape(-1,1))\n",
    "\n",
    "sc6 = StandardScaler()\n",
    "data_selected[\"net_cap_gain\"] = sc6.fit_transform(np.array(data_selected[\"net_cap_gain\"]).reshape(-1,1))\n",
    "\n",
    "sc7 = StandardScaler()\n",
    "data_selected[\"total_tax_liab\"] = sc7.fit_transform(np.array(data_selected[\"total_tax_liab\"]).reshape(-1,1))\n",
    "\n",
    "sc8 = StandardScaler()\n",
    "data_selected[\"2018-2010\"] = sc8.fit_transform(np.array(data_selected[\"2018-2010\"]).reshape(-1,1))\n",
    "\n",
    "sc9 = StandardScaler()\n",
    "data_selected[\"2010-2000\"] = sc9.fit_transform(np.array(data_selected[\"2010-2000\"]).reshape(-1,1))\n",
    "\n",
    "sc10 = StandardScaler()\n",
    "data_selected[\"2000-1990\"] = sc10.fit_transform(np.array(data_selected[\"2000-1990\"]).reshape(-1,1))\n",
    "\n",
    "sc11 = StandardScaler()\n",
    "data_selected[\"P/E_t0\"] = sc11.fit_transform(np.array(data_selected[\"P/E_t0\"]).reshape(-1,1))\n",
    "\n",
    "sc12 = StandardScaler()\n",
    "data_selected[\"unemp_t0\"] = sc12.fit_transform(np.array(data_selected[\"unemp_t0\"]).reshape(-1,1))\n",
    "\n",
    "sc13 = StandardScaler()\n",
    "data_selected[\"interest_rate_t0\"] = sc13.fit_transform(np.array(data_selected[\"interest_rate_t0\"]).reshape(-1,1))\n",
    "\n",
    "sc14 = StandardScaler()\n",
    "data_selected[\"GDPchange_t0\"] = sc14.fit_transform(np.array(data_selected[\"GDPchange_t0\"]).reshape(-1,1))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = set(data_selected.columns)\n",
    "cols.remove(\"LoanStatusCat\")\n",
    "col_list = list(cols)\n",
    "X = data_selected[col_list]\n",
    "Y = data_selected[\"LoanStatusCat\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = X.columns\n",
    "sc = StandardScaler()\n",
    "data_selected = pd.DataFrame(sc.fit_transform(X),columns = cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_selected.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, stratify = Y)\n",
    "x_val, x_test, y_val, y_test = train_test_split(x_test, y_test, test_size=0.5, random_state=0)\n",
    "cols = x_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm = SMOTE(ratio = 1.0)\n",
    "x_train, y_train = sm.fit_sample(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logisticRegr = LogisticRegression()\n",
    "logisticRegr.fit(x_train, y_train)\n",
    "train_preds = logisticRegr.predict(x_train)\n",
    "test_preds = logisticRegr.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "stats.chisqprob = lambda chisq, df: stats.chi2.sf(chisq, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = sma.Logit(y_train, x_train)\n",
    "result = model.fit()\n",
    "results_summary = result.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_as_html = results_summary.tables[1].as_html()\n",
    "table = pd.read_html(results_as_html, header=0, index_col=0)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table.index = list(X.columns)\n",
    "print(table.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_acc = np.sum(train_preds == y_train)/len(y_train)\n",
    "test_acc = np.sum(test_preds == y_test)/len(y_test)\n",
    "print(\"Training Accuracy is: \", train_acc)\n",
    "print(\"Testing Accuracy is: \", test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test,test_preds)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9,9))\n",
    "sns.heatmap(cm, annot=True, fmt=\".0f\", linewidths=.5, square = True, cmap = 'Blues_r');\n",
    "plt.ylabel('Actual label');\n",
    "plt.xlabel('Predicted label');\n",
    "all_sample_title = 'Test Accuracy Score: {0}'.format(test_acc)\n",
    "plt.title(all_sample_title, size = 15);\n",
    "plt.savefig(\"Confusion_matrix_lr_final.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc = roc_curve(y_test,test_preds)\n",
    "roc_train = roc_curve(y_train,train_preds)\n",
    "sns.set_style(\"darkgrid\")\n",
    "plt.plot(roc[0],roc[1],label = \"test\")\n",
    "plt.plot(roc_train[0],roc_train[1],label = \"train\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC Curve\")\n",
    "plt.legend()\n",
    "#plt.savefig(\"lr_roc_final.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_score = auc(roc[0],roc[1])\n",
    "print(\"Logistic Regression Test AUC Score is: \", auc_score)\n",
    "\n",
    "auc_train_score = auc(roc_train[0],roc_train[1])\n",
    "print(\"Logistic Regression Train AUC Score is: \", auc_train_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_import = logisticRegr.coef_[0]\n",
    "col_names = cols\n",
    "order = np.argsort(feat_import)[::-1]\n",
    "feat_import = feat_import[order]\n",
    "col_names = col_names[order]\n",
    "\n",
    "for i in range(len(feat_import)):\n",
    "    print(\"Feature \",col_names[i], \"has an importance of: \", feat_import[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(1000,n_jobs = -1,max_depth = 10)\n",
    "rf.fit(x_train,y_train)\n",
    "train_preds = rf.predict(x_train)\n",
    "test_preds = rf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_acc = np.sum(train_preds == y_train)/len(y_train)\n",
    "test_acc = np.sum(test_preds == y_test)/len(y_test)\n",
    "print(\"Training Accuracy is: \", train_acc)\n",
    "print(\"Testing Accuracy is: \", test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_import = rf.feature_importances_\n",
    "col_names = cols\n",
    "order = np.argsort(feat_import)[::-1]\n",
    "feat_import = feat_import[order]\n",
    "col_names = col_names[order]\n",
    "\n",
    "for i in range(len(feat_import)):\n",
    "    print(\"Feature \",col_names[i], \"has an importance of: \", feat_import[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test,test_preds)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9,9))\n",
    "sns.heatmap(cm, annot=True, fmt=\".0f\", linewidths=.5, square = True, cmap = 'Blues_r');\n",
    "plt.ylabel('Actual label');\n",
    "plt.xlabel('Predicted label');\n",
    "all_sample_title = 'Test Accuracy Score: {0}'.format(test_acc)\n",
    "plt.title(all_sample_title, size = 15);\n",
    "#plt.savefig(\"Confusion_matrix_rf_final.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc = roc_curve(y_test,test_preds)\n",
    "roc_train = roc_curve(y_train,train_preds)\n",
    "sns.set_style(\"darkgrid\")\n",
    "plt.plot(roc[0],roc[1],label = \"test\")\n",
    "plt.plot(roc_train[0],roc_train[1],label = \"train\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC Curve\")\n",
    "plt.legend()\n",
    "plt.savefig(\"rf_roc_final.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_score = auc(roc[0],roc[1])\n",
    "print(\"Random Forest Test AUC Score is: \", auc_score)\n",
    "\n",
    "auc_train_score = auc(roc_train[0],roc_train[1])\n",
    "print(\"Random Forest Train AUC Score is: \", auc_train_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Neural Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val, x_test, y_val, y_test = train_test_split(x_test, y_test, test_size=0.5, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "dims = x_train.shape[1]\n",
    "\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Dense(32, input_dim=dims))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Dense(64,activation = \"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Dense(128,activation = \"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(64,activation = \"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Dense(32,activation = \"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Dense(1,activation = \"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 40\n",
    "b_size = 256\n",
    "es = EarlyStopping(monitor='val_loss', mode='min')\n",
    "optim = Adam(lr = 0.001)\n",
    "model.compile(optimizer = optim, metrics = [\"accuracy\"],loss = \"binary_crossentropy\")\n",
    "#print(model.summary())\n",
    "\n",
    "#model.fit(x_train,y_train,batch_size = b_size, epochs = num_epochs,callbacks = [es],validation_data = (x_val,y_val))\n",
    "model.fit(x_train,y_train,batch_size = b_size, epochs = num_epochs,validation_data = (x_val,y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preds = model.predict(x_train)\n",
    "test_preds = model.predict(x_test)\n",
    "train_preds = (train_preds > 0.5).astype(int).flatten()\n",
    "test_preds = (test_preds > 0.5).astype(int).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_acc = np.sum(train_preds == y_train)/len(y_train)\n",
    "test_acc = np.sum(test_preds == y_test)/len(y_test)\n",
    "print(\"Training Accuracy is: \", train_acc)\n",
    "print(\"Testing Accuracy is: \", test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test,test_preds)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9,9))\n",
    "sns.heatmap(cm, annot=True, fmt=\".0f\", linewidths=.5, square = True, cmap = 'Blues_r');\n",
    "plt.ylabel('Actual label');\n",
    "plt.xlabel('Predicted label');\n",
    "all_sample_title = 'Test Accuracy Score: {0}'.format(0.8142932676518884)\n",
    "plt.title(all_sample_title, size = 15);\n",
    "#plt.savefig(\"Confusion_matrix_nn_final.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc = roc_curve(y_test,test_preds)\n",
    "roc_train = roc_curve(y_train,train_preds)\n",
    "sns.set_style(\"darkgrid\")\n",
    "plt.plot(roc[0],roc[1],label = \"test\")\n",
    "plt.plot(roc_train[0],roc_train[1],label = \"train\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC Curve\")\n",
    "plt.legend()\n",
    "plt.savefig(\"nn_roc_final.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_score = auc(roc[0],roc[1])\n",
    "print(\"Neural Network Test AUC Score is: \", auc_score)\n",
    "\n",
    "auc_train_score = auc(roc_train[0],roc_train[1])\n",
    "print(\"Neural Network Train AUC Score is: \", auc_train_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
